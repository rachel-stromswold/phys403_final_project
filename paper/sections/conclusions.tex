\section{Discussion} \label{sec:conclusions}

In this paper we have considered a measurement of the Hubble constant $H_0$ using the luminosity distances of binary black hole mergers estimated from their gravitational wave signals.
By simulating the effects of future detections using a physically plausible (though simplified) model of galaxy clusters, we determine that the constraints resulting from such measurements can become considerably smaller.
In particular, we find that after $96\pm 2$ detections with sufficient sky localization, the standard deviation on the measurement of $H_0$ could reach roughly $5$ \si{km.s^{-1}.Mpc^{-1}}.

This measurement of $H_0$ is independent of the standard candles used in other calculations, and thus presents a possible means of confirming or rejecting these other calculations, which are in tension with one another.
However, careful consideration must be given to systematic biases and uncertainties in this analysis.
In particular we see a strong correlation between the measured value of $H_0$ for a particular event and the standard deviation associated with that measurement, as shown in Figure \ref{fig:correlation}.
The origin of this correlation is likely to be some systematic bias in the analysis, and future work should determine whether this bias would be present in real data or if it is a result of our simplified galaxy cluster model.


%\footnote{The code for all simulations presented here can be found at: \textbf{REDACTED}}.%\href{https://github.com/rachel-stromswold/phys403_final_project}{\url{https://github.com/rachel-stromswold/phys403_final_project}}.}.


